# ğŸš€ Smart Transportation

## ğŸŒŸ Overview
Smart Transportation is a data-driven solution designed to optimize and enhance transportation systems using advanced analytics and big data technologies. This project leverages tools such as Apache Spark and Redshift to process, analyze, and visualize large-scale transportation data, providing actionable insights for smarter decision-making.

## âœ¨ Features
- **Big Data Processing**: Efficiently process and analyze large transportation datasets using Apache Spark.
- **Database Integration**: Utilize AWS Redshift for scalable data storage and querying.
- **Containerized Deployment**: Simplify deployment with Docker Compose.
- **Configurable Jobs**: Modular and configurable Python scripts for various data processing tasks.

## ğŸ“‚ File Structure
```
Smart-Transportation
â”œâ”€â”€ LICENSE                 # Licensing information
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ docker-compose.yml      # Docker setup for the project
â”œâ”€â”€ redshift-query.sql      # SQL queries for Redshift database
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ jobs/                   # Python scripts for data processing
â”‚   â”œâ”€â”€ config.py           # Configuration file
â”‚   â”œâ”€â”€ main.py             # Main job execution script
â”‚   â”œâ”€â”€ spark-transporation.py  # Spark job for transportation data processing
â”‚   â””â”€â”€ __pycache__/        # Compiled Python cache files
â””â”€â”€ .git/                   # Git repository metadata
```

## ğŸ› ï¸ Technologies Used
- **Apache Spark**: For big data processing and analytics.
- **AWS Redshift**: For scalable database storage and querying.
- **Docker**: For containerization and simplified deployment.
- **Python**: For data processing scripts.
- **SQL**: For database querying and management.

## ğŸ“‹ Prerequisites
To set up and run the project, ensure you have the following installed:
- ğŸ³ Docker
- ğŸ Python 3.11 or higher (Only this version is tested and compatible. Consider downgrading or upgrading to this version for smooth execution.)
- ğŸ›¢ï¸ AWS Redshift (or equivalent database access)

## âš™ï¸ Installation

### 1. ğŸŒ Set up AWS Account
1. Create an AWS account by visiting [AWS Sign-Up](https://aws.amazon.com/free/).
2. Log in to your AWS Management Console.
3. Navigate to **IAM (Identity and Access Management)** to create a new user with programmatic access.
4. Attach the appropriate policies (e.g., AmazonRedshiftFullAccess).
5. Note down the **Access Key ID** and **Secret Access Key**.

### 2. ğŸ›¢ï¸ Set up AWS Redshift
1. Go to the Redshift section in the AWS Management Console.
2. Click on **Create cluster** and configure the following:
   - **Cluster identifier**: A unique name for your cluster.
   - **Node type**: Choose the node size as per your dataset.
   - **Number of nodes**: For testing, you can start with 1.
   - **Database name**: Set the database name (e.g., `transportation_db`).
3. Wait for the cluster to be available.
4. Note down the **Endpoint** of your cluster (found in the cluster details page).
5. Configure your security group to allow connections from your machine by editing the inbound rules.

### 3. ğŸ³ Set up Docker
1. Install Docker by following instructions for your operating system from [Docker's website](https://www.docker.com/).
2. Verify the installation by running:
   ```bash
   docker --version
   ```

### 4. ğŸ“¦ Clone the Repository
   ```bash
   git clone <repository-url>
   cd Smart-Transportation
   ```

### 5. ğŸ“‹ Install Python Dependencies
   ```bash
   pip install -r requirements.txt
   ```

### 6. ğŸ”§ Configure the Project
1. Open `jobs/config.py` and update the following fields:
   - AWS Access Key and Secret Key
   - Redshift cluster endpoint and database details
   - S3 bucket details (if using S3 for data input/output)

### 7. ğŸ³ Start the Docker Containers
   ```bash
   docker compose up -d
   ```

## ğŸš€ Usage

### âš¡ Running Spark Jobs
Run the main job script to process transportation data:
```bash
python jobs/main.py
```

### ğŸ›¢ï¸ Querying Data
Use the `redshift-query.sql` script to query the processed data in AWS Redshift:
```sql
-- Example query
SELECT * FROM transportation_data LIMIT 10;
```

### ğŸ³ Docker Management
To bring up the Docker containers:
```bash
docker-compose up
```
To shut down the Docker containers:
```bash
docker-compose down
```

## ğŸ¤ Contributing
Contributions are welcome! Please fork the repository and submit a pull request with your changes.

## ğŸ“œ License
This project is licensed under the MIT License. See the `LICENSE` file for details.

## ğŸ“ Contact
For any questions or support, please reach out to the contributors or open an issue in the repository.
